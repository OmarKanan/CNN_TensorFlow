{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import functools\n",
    "from time import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils\n",
    "import data_reader\n",
    "from batch_norm import Batch_Normalizer\n",
    "from model import CNN_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# File parameters\n",
    "DATA_DIR = 'data'\n",
    "TRAIN_IMAGES = 'data_train.bin'\n",
    "TRAIN_TEMPLATES = 'fv_train.bin'\n",
    "VALID_IMAGES = 'data_valid.bin'\n",
    "VALID_TEMPLATES = 'fv_valid.bin'\n",
    "TEST_IMAGES = 'data_test.bin'\n",
    "\n",
    "# Data parameters\n",
    "NUM_TRAIN_IMAGES = 100000\n",
    "NUM_VALID_IMAGES = 10000\n",
    "NUM_TEST_IMAGES = 10000\n",
    "IMAGE_DIM = 48\n",
    "TEMPLATE_DIM = 128\n",
    "\n",
    "# Batch parameters\n",
    "BATCH_SIZE = 100\n",
    "VALID_BATCH_SIZE = 1000\n",
    "\n",
    "# Batch norm parameters\n",
    "EMA_DECAY = 0.99\n",
    "BN_EPSILON = 0.01\n",
    "\n",
    "# Log parameters\n",
    "LOG_DIR = 'logs'\n",
    "SAVE_DIR = 'checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run1():\n",
    "    model = CNN_Model('config3', DATA_DIR, LOG_DIR, SAVE_DIR, IMAGE_DIM, TEMPLATE_DIM, TRAIN_IMAGES, TRAIN_TEMPLATES, \n",
    "                      VALID_IMAGES, VALID_TEMPLATES, NUM_TRAIN_IMAGES, NUM_VALID_IMAGES, EMA_DECAY, BN_EPSILON)\n",
    "\n",
    "    model.add_conv('conv_1_1', ksize=[3, 3, 1, 10])\n",
    "    model.add_batch_norm('bn_1_1')\n",
    "    model.add_conv('conv_1_2', ksize=[3, 3, 10, 10])\n",
    "    model.add_pool('max_pool_1', 'max', ksize=[1, 2, 2, 1], stride=[1, 2, 2, 1])\n",
    "    model.add_batch_norm('bn_1_2')\n",
    "\n",
    "    model.add_conv('conv_2_1', ksize=[3, 3, 10, 20])\n",
    "    model.add_batch_norm('bn_2_1')\n",
    "    model.add_conv('conv_2_2', ksize=[3, 3, 20, 20])\n",
    "    model.add_pool('max_pool_2', 'max', ksize=[1, 2, 2, 1], stride=[1, 2, 2, 1])\n",
    "    model.add_batch_norm('bn_2_2')\n",
    "\n",
    "    model.add_conv('conv_3_1', ksize=[3, 3, 20, 40])\n",
    "    model.add_batch_norm('bn_3_1')\n",
    "    model.add_conv('conv_3_2', ksize=[3, 3, 40, 40])\n",
    "    model.add_pool('avg_pool_3', 'avg', ksize=[1, 6, 6, 1], stride=[1, 6, 6, 1])\n",
    "    model.add_batch_norm('bn_3_2')\n",
    "\n",
    "    model.add_fully_connected('fc', size=128)\n",
    "\n",
    "    model.add_mse_loss('mse_loss')\n",
    "    model.add_adam_optimizer('optimizer', init_learning_rate=0.005, decay=False)\n",
    "    model.add_summaries('summaries')\n",
    "\n",
    "    \n",
    "    utils.add_description(\"\"\"\n",
    "    model = CNN_Model('config3', DATA_DIR, LOG_DIR, SAVE_DIR, IMAGE_DIM, TEMPLATE_DIM, TRAIN_IMAGES, TRAIN_TEMPLATES, \n",
    "                      VALID_IMAGES, VALID_TEMPLATES, NUM_TRAIN_IMAGES, NUM_VALID_IMAGES, EMA_DECAY, BN_EPSILON)\n",
    "\n",
    "    model.add_conv('conv_1_1', ksize=[3, 3, 1, 10])\n",
    "    model.add_batch_norm('bn_1_1')\n",
    "    model.add_conv('conv_1_2', ksize=[3, 3, 10, 10])\n",
    "    model.add_pool('max_pool_1', 'max', ksize=[1, 2, 2, 1], stride=[1, 2, 2, 1])\n",
    "    model.add_batch_norm('bn_1_2')\n",
    "\n",
    "    model.add_conv('conv_2_1', ksize=[3, 3, 10, 20])\n",
    "    model.add_batch_norm('bn_2_1')\n",
    "    model.add_conv('conv_2_2', ksize=[3, 3, 20, 20])\n",
    "    model.add_pool('max_pool_2', 'max', ksize=[1, 2, 2, 1], stride=[1, 2, 2, 1])\n",
    "    model.add_batch_norm('bn_2_2')\n",
    "\n",
    "    model.add_conv('conv_3_1', ksize=[3, 3, 20, 40])\n",
    "    model.add_batch_norm('bn_3_1')\n",
    "    model.add_conv('conv_3_2', ksize=[3, 3, 40, 40])\n",
    "    model.add_pool('avg_pool_3', 'avg', ksize=[1, 6, 6, 1], stride=[1, 6, 6, 1])\n",
    "    model.add_batch_norm('bn_3_2')\n",
    "\n",
    "    model.add_fully_connected('fc', size=128)\n",
    "\n",
    "    model.add_mse_loss('mse_loss')\n",
    "    model.add_adam_optimizer('optimizer', init_learning_rate=0.005, decay=False)\n",
    "    model.add_summaries('summaries')\n",
    "\n",
    "    total parameters = %d\n",
    "    \"\"\"  % (utils.num_parameters(model)), model.save_dir, model.name)\n",
    "    \n",
    "    \n",
    "    model.initialize_session(restore=True)\n",
    "    model.train(n_batches=10000, step_size=500, batch_size=100, valid_batch_size=1000, save=True)\n",
    "    model.close_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description added at checkpoints\\config3\\config3_description.txt\n",
      "Restored session checkpoints\\config3\\model.ckpt-28000\n",
      "Batch 28500:\n",
      "--> Train loss = 0.006013\n",
      "--> Valid loss = 0.006749\n",
      "Saving session checkpoints\\config3\\model.ckpt-28500\n",
      "Batch 29000:\n",
      "--> Train loss = 0.006000\n",
      "--> Valid loss = 0.006762\n",
      "Saving session checkpoints\\config3\\model.ckpt-29000\n",
      "Batch 29500:\n",
      "--> Train loss = 0.005993\n",
      "--> Valid loss = 0.006770\n",
      "Saving session checkpoints\\config3\\model.ckpt-29500\n",
      "Batch 30000:\n",
      "--> Train loss = 0.005998\n",
      "--> Valid loss = 0.006806\n",
      "Saving session checkpoints\\config3\\model.ckpt-30000\n",
      "Batch 30500:\n",
      "--> Train loss = 0.005992\n",
      "--> Valid loss = 0.006773\n",
      "Saving session checkpoints\\config3\\model.ckpt-30500\n",
      "Batch 31000:\n",
      "--> Train loss = 0.005984\n",
      "--> Valid loss = 0.006765\n",
      "Saving session checkpoints\\config3\\model.ckpt-31000\n",
      "Batch 31500:\n",
      "--> Train loss = 0.005984\n",
      "--> Valid loss = 0.006727\n",
      "Saving session checkpoints\\config3\\model.ckpt-31500\n",
      "Batch 32000:\n",
      "--> Train loss = 0.005982\n",
      "--> Valid loss = 0.006739\n",
      "Saving session checkpoints\\config3\\model.ckpt-32000\n",
      "Batch 32500:\n",
      "--> Train loss = 0.005987\n",
      "--> Valid loss = 0.006743\n",
      "Saving session checkpoints\\config3\\model.ckpt-32500\n",
      "Batch 33000:\n",
      "--> Train loss = 0.005988\n",
      "--> Valid loss = 0.006734\n",
      "Saving session checkpoints\\config3\\model.ckpt-33000\n",
      "Batch 33500:\n",
      "--> Train loss = 0.005978\n",
      "--> Valid loss = 0.006730\n",
      "Saving session checkpoints\\config3\\model.ckpt-33500\n",
      "Batch 34000:\n",
      "--> Train loss = 0.005975\n",
      "--> Valid loss = 0.006732\n",
      "Saving session checkpoints\\config3\\model.ckpt-34000\n",
      "Batch 34500:\n",
      "--> Train loss = 0.005974\n",
      "--> Valid loss = 0.006762\n",
      "Saving session checkpoints\\config3\\model.ckpt-34500\n",
      "Batch 35000:\n",
      "--> Train loss = 0.005970\n",
      "--> Valid loss = 0.006722\n",
      "Saving session checkpoints\\config3\\model.ckpt-35000\n",
      "Batch 35500:\n",
      "--> Train loss = 0.005967\n",
      "--> Valid loss = 0.006753\n",
      "Saving session checkpoints\\config3\\model.ckpt-35500\n",
      "Batch 36000:\n",
      "--> Train loss = 0.005968\n",
      "--> Valid loss = 0.006706\n",
      "Saving session checkpoints\\config3\\model.ckpt-36000\n",
      "Batch 36500:\n",
      "--> Train loss = 0.005973\n",
      "--> Valid loss = 0.006701\n",
      "Saving session checkpoints\\config3\\model.ckpt-36500\n",
      "Batch 37000:\n",
      "--> Train loss = 0.005957\n",
      "--> Valid loss = 0.006716\n",
      "Saving session checkpoints\\config3\\model.ckpt-37000\n",
      "Batch 37500:\n",
      "--> Train loss = 0.005956\n",
      "--> Valid loss = 0.006738\n",
      "Saving session checkpoints\\config3\\model.ckpt-37500\n",
      "Batch 38000:\n",
      "--> Train loss = 0.005954\n",
      "--> Valid loss = 0.006722\n",
      "Saving session checkpoints\\config3\\model.ckpt-38000\n"
     ]
    }
   ],
   "source": [
    "run1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = CNN_Model('config6', DATA_DIR, LOG_DIR, SAVE_DIR, IMAGE_DIM, TEMPLATE_DIM, TRAIN_IMAGES, TRAIN_TEMPLATES, \n",
    "#                   VALID_IMAGES, VALID_TEMPLATES, NUM_TRAIN_IMAGES, NUM_VALID_IMAGES, EMA_DECAY, BN_EPSILON)\n",
    "\n",
    "# model.add_conv('conv_1', ksize=[3, 3, 1, 16])\n",
    "# model.add_pool('pool_1', 'max', ksize=[1, 2, 2, 1], stride=[1, 2, 2, 1])\n",
    "# model.add_batch_norm('bn_1')\n",
    "\n",
    "# model.add_conv('conv_2', ksize=[3, 3, 16, 32])\n",
    "# model.add_pool('pool_2', 'max', ksize=[1, 2, 2, 1], stride=[1, 2, 2, 1])\n",
    "# model.add_batch_norm('bn_2')\n",
    "\n",
    "# model.add_conv('conv_3', ksize=[3, 3, 32, 32])\n",
    "# model.add_pool('pool_3', 'max', ksize=[1, 2, 2, 1], stride=[1, 2, 2, 1])\n",
    "# model.add_batch_norm('bn_3')\n",
    "\n",
    "# model.add_conv('conv_4', ksize=[3, 3, 32, 32])\n",
    "# model.add_pool('pool_4', 'max', ksize=[1, 2, 2, 1], stride=[1, 2, 2, 1])\n",
    "# model.add_batch_norm('bn_4')\n",
    "\n",
    "# model.add_conv('conv_5', ksize=[3, 3, 32, 62])\n",
    "# model.add_pool('pool_5', 'max', ksize=[1, 3, 3, 1], stride=[1, 3, 3, 1])\n",
    "# model.add_batch_norm('bn_5')\n",
    "\n",
    "# model.add_fully_connected('fc', size=128)\n",
    "\n",
    "# model.add_mse_loss('mse_loss')\n",
    "# model.add_adam_optimizer('optimizer', init_learning_rate=0.0005, decay=False)\n",
    "# model.add_summaries('summaries')\n",
    "\n",
    "\n",
    "# test_images, _ = data_reader.load_data(DATA_DIR, TEST_IMAGES, VALID_TEMPLATES, NUM_TEST_IMAGES, IMAGE_DIM, TEMPLATE_DIM)\n",
    "# predictions = model.predict(test_images, batch_size=1000)\n",
    "\n",
    "# f = open('data/template_pred_config6.bin', 'wb')\n",
    "# for i in range(NUM_TEST_IMAGES):\n",
    "#     f.write(predictions[i, :])\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
